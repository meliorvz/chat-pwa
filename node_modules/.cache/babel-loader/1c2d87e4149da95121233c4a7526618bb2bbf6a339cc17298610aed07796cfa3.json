{"ast":null,"code":"import _objectSpread from \"/Users/victor/Documents/Sublime/claude_api_project/chat-pwa/node_modules/@babel/runtime/helpers/esm/objectSpread2.js\";\n// File generated from our OpenAPI spec by Stainless.\nimport { APIResource } from '@anthropic-ai/sdk/resource';\nexport class Completions extends APIResource {\n  create(body, options) {\n    var _body$stream;\n    return this._client.post('/v1/complete', _objectSpread(_objectSpread({\n      body,\n      timeout: 600000\n    }, options), {}, {\n      stream: (_body$stream = body.stream) !== null && _body$stream !== void 0 ? _body$stream : false\n    }));\n  }\n}\n(function (Completions) {})(Completions || (Completions = {}));","map":{"version":3,"names":["APIResource","Completions","create","body","options","_body$stream","_client","post","_objectSpread","timeout","stream"],"sources":["/Users/victor/Documents/Sublime/claude_api_project/chat-pwa/node_modules/@anthropic-ai/sdk/src/resources/completions.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless.\n\nimport * as Core from \"../core\";\nimport { APIPromise } from \"../core\";\nimport { APIResource } from \"../resource\";\nimport * as CompletionsAPI from \"./completions\";\nimport { Stream } from \"../streaming\";\n\nexport class Completions extends APIResource {\n  /**\n   * [Legacy] Create a Text Completion.\n   *\n   * The Text Completions API is a legacy API. We recommend using the\n   * [Messages API](https://docs.anthropic.com/claude/reference/messages_post) going\n   * forward.\n   *\n   * Future models and features will not be compatible with Text Completions. See our\n   * [migration guide](https://docs.anthropic.com/claude/reference/migrating-from-text-completions-to-messages)\n   * for guidance in migrating from Text Completions to Messages.\n   */\n  create(body: CompletionCreateParamsNonStreaming, options?: Core.RequestOptions): APIPromise<Completion>;\n  create(\n    body: CompletionCreateParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<Completion>>;\n  create(\n    body: CompletionCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<Completion> | Completion>;\n  create(\n    body: CompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<Completion> | APIPromise<Stream<Completion>> {\n    return this._client.post('/v1/complete', {\n      body,\n      timeout: 600000,\n      ...options,\n      stream: body.stream ?? false,\n    }) as APIPromise<Completion> | APIPromise<Stream<Completion>>;\n  }\n}\n\nexport interface Completion {\n  /**\n   * Unique object identifier.\n   *\n   * The format and length of IDs may change over time.\n   */\n  id: string;\n\n  /**\n   * The resulting completion up to and excluding the stop sequences.\n   */\n  completion: string;\n\n  /**\n   * The model that handled the request.\n   */\n  model: string;\n\n  /**\n   * The reason that we stopped.\n   *\n   * This may be one the following values:\n   *\n   * - `\"stop_sequence\"`: we reached a stop sequence â€” either provided by you via the\n   *   `stop_sequences` parameter, or a stop sequence built into the model\n   * - `\"max_tokens\"`: we exceeded `max_tokens_to_sample` or the model's maximum\n   */\n  stop_reason: string | null;\n\n  /**\n   * Object type.\n   *\n   * For Text Completions, this is always `\"completion\"`.\n   */\n  type: 'completion';\n}\n\nexport type CompletionCreateParams = CompletionCreateParamsNonStreaming | CompletionCreateParamsStreaming;\n\nexport interface CompletionCreateParamsBase {\n  /**\n   * The maximum number of tokens to generate before stopping.\n   *\n   * Note that our models may stop _before_ reaching this maximum. This parameter\n   * only specifies the absolute maximum number of tokens to generate.\n   */\n  max_tokens_to_sample: number;\n\n  /**\n   * The model that will complete your prompt.\n   *\n   * See [models](https://docs.anthropic.com/claude/docs/models-overview) for\n   * additional details and options.\n   */\n  model: (string & {}) | 'claude-2.0' | 'claude-2.1' | 'claude-instant-1.2';\n\n  /**\n   * The prompt that you want Claude to complete.\n   *\n   * For proper response generation you will need to format your prompt using\n   * alternating `\\n\\nHuman:` and `\\n\\nAssistant:` conversational turns. For example:\n   *\n   * ```\n   * \"\\n\\nHuman: {userQuestion}\\n\\nAssistant:\"\n   * ```\n   *\n   * See\n   * [prompt validation](https://anthropic.readme.io/claude/reference/prompt-validation)\n   * and our guide to\n   * [prompt design](https://docs.anthropic.com/claude/docs/introduction-to-prompt-design)\n   * for more details.\n   */\n  prompt: string;\n\n  /**\n   * An object describing metadata about the request.\n   */\n  metadata?: CompletionCreateParams.Metadata;\n\n  /**\n   * Sequences that will cause the model to stop generating.\n   *\n   * Our models stop on `\"\\n\\nHuman:\"`, and may include additional built-in stop\n   * sequences in the future. By providing the stop_sequences parameter, you may\n   * include additional strings that will cause the model to stop generating.\n   */\n  stop_sequences?: Array<string>;\n\n  /**\n   * Whether to incrementally stream the response using server-sent events.\n   *\n   * See\n   * [streaming](https://docs.anthropic.com/claude/reference/text-completions-streaming)\n   * for details.\n   */\n  stream?: boolean;\n\n  /**\n   * Amount of randomness injected into the response.\n   *\n   * Defaults to `1.0`. Ranges from `0.0` to `1.0`. Use `temperature` closer to `0.0`\n   * for analytical / multiple choice, and closer to `1.0` for creative and\n   * generative tasks.\n   *\n   * Note that even with `temperature` of `0.0`, the results will not be fully\n   * deterministic.\n   */\n  temperature?: number;\n\n  /**\n   * Only sample from the top K options for each subsequent token.\n   *\n   * Used to remove \"long tail\" low probability responses.\n   * [Learn more technical details here](https://towardsdatascience.com/how-to-sample-from-language-models-682bceb97277).\n   *\n   * Recommended for advanced use cases only. You usually only need to use\n   * `temperature`.\n   */\n  top_k?: number;\n\n  /**\n   * Use nucleus sampling.\n   *\n   * In nucleus sampling, we compute the cumulative distribution over all the options\n   * for each subsequent token in decreasing probability order and cut it off once it\n   * reaches a particular probability specified by `top_p`. You should either alter\n   * `temperature` or `top_p`, but not both.\n   *\n   * Recommended for advanced use cases only. You usually only need to use\n   * `temperature`.\n   */\n  top_p?: number;\n}\n\nexport namespace CompletionCreateParams {\n  /**\n   * An object describing metadata about the request.\n   */\n  export interface Metadata {\n    /**\n     * An external identifier for the user who is associated with the request.\n     *\n     * This should be a uuid, hash value, or other opaque identifier. Anthropic may use\n     * this id to help detect abuse. Do not include any identifying information such as\n     * name, email address, or phone number.\n     */\n    user_id?: string | null;\n  }\n\n  export type CompletionCreateParamsNonStreaming = CompletionsAPI.CompletionCreateParamsNonStreaming;\n  export type CompletionCreateParamsStreaming = CompletionsAPI.CompletionCreateParamsStreaming;\n}\n\nexport interface CompletionCreateParamsNonStreaming extends CompletionCreateParamsBase {\n  /**\n   * Whether to incrementally stream the response using server-sent events.\n   *\n   * See\n   * [streaming](https://docs.anthropic.com/claude/reference/text-completions-streaming)\n   * for details.\n   */\n  stream?: false;\n}\n\nexport interface CompletionCreateParamsStreaming extends CompletionCreateParamsBase {\n  /**\n   * Whether to incrementally stream the response using server-sent events.\n   *\n   * See\n   * [streaming](https://docs.anthropic.com/claude/reference/text-completions-streaming)\n   * for details.\n   */\n  stream: true;\n}\n\nexport namespace Completions {\n  export import Completion = CompletionsAPI.Completion;\n  export import CompletionCreateParams = CompletionsAPI.CompletionCreateParams;\n  export import CompletionCreateParamsNonStreaming = CompletionsAPI.CompletionCreateParamsNonStreaming;\n  export import CompletionCreateParamsStreaming = CompletionsAPI.CompletionCreateParamsStreaming;\n}\n"],"mappings":";AAAA;SAISA,WAAW,QAAQ,4BAA4B;AAIxD,OAAM,MAAOC,WAAY,SAAQD,WAAW;EAqB1CE,MAAMA,CACJC,IAA4B,EAC5BC,OAA6B;IAAA,IAAAC,YAAA;IAE7B,OAAO,IAAI,CAACC,OAAO,CAACC,IAAI,CAAC,cAAc,EAAAC,aAAA,CAAAA,aAAA;MACrCL,IAAI;MACJM,OAAO,EAAE;IAAM,GACZL,OAAO;MACVM,MAAM,GAAAL,YAAA,GAAEF,IAAI,CAACO,MAAM,cAAAL,YAAA,cAAAA,YAAA,GAAI;IAAK,EAC7B,CAA4D;EAC/D;;AAkLF,WAAiBJ,WAAW,GAK5B,CAAC,EALgBA,WAAW,KAAXA,WAAW","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}